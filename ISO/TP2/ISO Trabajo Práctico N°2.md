## a. ¬øQu√© es un Sistema Operativo?
Un **Sistema Operativo (SO)** es el software fundamental que gestiona los recursos de _hardware_ y proporciona servicios comunes para los programas de aplicaci√≥n. Act√∫a como intermediario entre el usuario/aplicaciones y el _hardware_ de la computadora.
## b. Enumere qu√© componentes/aspectos del Hardware son necesarios para cumplir los objetivos de un sistema operativo
Para que un Sistema Operativo pueda cumplir sus objetivos de gesti√≥n y servicio, necesita interaccionar y controlar los siguientes aspectos o componentes principales del _hardware_:

- **Unidad Central de Procesamiento (CPU):** Es el "cerebro" de la computadora. El SO gestiona el tiempo de la CPU (planificaci√≥n de procesos) para que los diferentes programas puedan ejecutarse.
    
- **Memoria Principal (RAM):** El SO administra el espacio de memoria, asignando porciones a los programas y asegur√°ndose de que no interfieran entre s√≠.
    
- **Dispositivos de Entrada/Salida (E/S):** Incluyen teclado, rat√≥n, pantalla, impresoras, discos duros, etc. El SO proporciona _drivers_ y mecanismos para controlar y coordinar el acceso a estos dispositivos.
    
- **Almacenamiento Secundario:** Discos duros (HDD/SSD). El SO implementa y gestiona el **Sistema de Archivos** para organizar y almacenar datos de forma persistente.
    
- **Controladores de Dispositivo:** Circuitos electr√≥nicos que permiten a la CPU comunicarse con los dispositivos perif√©ricos. El SO interact√∫a con ellos a trav√©s de _drivers_ (controladores de software).
    
- **Mecanismos de Protecci√≥n:** Aspectos del _hardware_ (como modos de operaci√≥n de la CPU o protecci√≥n de memoria) que permiten al SO protegerse a s√≠ mismo y a los diferentes programas de errores o accesos no autorizados.
## c. Enumere componentes de un Sistema Operativo
Los componentes principales que forman la estructura de un Sistema Operativo son:

1. **N√∫cleo (_Kernel_):** Es el coraz√≥n del SO. Realiza las funciones esenciales de bajo nivel, como:
    
    - Gesti√≥n de procesos (creaci√≥n, planificaci√≥n, finalizaci√≥n).
        
    - Gesti√≥n de memoria.
        
    - Gesti√≥n de E/S.
        
    - Manejo de interrupciones y llamadas al sistema.
        
2. **Sistema de Archivos:** Es el encargado de organizar, nombrar, almacenar y recuperar archivos en los dispositivos de almacenamiento.
    
3. **Gestor de Memoria:** Controla la memoria principal, decidiendo qu√© procesos se cargan en la RAM, d√≥nde se ubican y c√≥mo se protegen entre s√≠.
    
4. **Gestor de E/S (Entrada/Salida):** Se encarga de la comunicaci√≥n entre el sistema y los dispositivos perif√©ricos (a trav√©s de los _drivers_ o controladores de dispositivo).
    
5. **Planificador de Procesos/Tareas (_Scheduler_):** Determina qu√© proceso obtendr√° el uso de la CPU en un momento dado, optimizando el rendimiento y la respuesta del sistema.
    
6. **Sistema de Protecci√≥n y Seguridad:** Mecanismos para controlar el acceso a los recursos del sistema y evitar interferencias o da√±os (ej. gesti√≥n de permisos de usuario).
    
7. **Interfaz de Usuario (_Shell_ o GUI):** Es la forma en que el usuario interact√∫a con el SO. Puede ser una **Interfaz Gr√°fica de Usuario (GUI)** (como el escritorio de Windows o macOS) o una **Interfaz de L√≠nea de Comandos (CLI)** (_shell_ de Linux/Unix).
    
8. **Utilidades del Sistema:** Programas que facilitan las tareas de mantenimiento y administraci√≥n (ej. formateadores de disco, herramientas de diagn√≥stico, copias de seguridad).
## d.¬øQue es una llamada al sistema (system call)? ¬øC√≥mo es posible implementarlas?
Una **llamada al sistema** es el mecanismo mediante el cual un programa de aplicaci√≥n solicita un servicio al **Sistema Operativo (SO)**, espec√≠ficamente al **n√∫cleo (_kernel_)**. Estos servicios incluyen la gesti√≥n de recursos de _hardware_ (como E/S de archivos, asignaci√≥n de memoria, creaci√≥n de procesos, etc.) a los que el programa no puede acceder directamente por motivos de seguridad y protecci√≥n.

### Implementaci√≥n

La implementaci√≥n de una llamada al sistema se realiza de la siguiente manera:

1. **Transici√≥n de Modo:** El _hardware_ del procesador soporta al menos dos modos de operaci√≥n: el **modo usuario** (donde se ejecutan las aplicaciones) y el **modo _kernel_/** _supervisor_ (donde se ejecuta el SO).
    
2. **Instrucci√≥n Especial:** El programa ejecuta una **instrucci√≥n de _hardware_** especial (como `TRAP` o **interrupci√≥n por _software_**) que cambia la CPU de **modo usuario a modo _kernel_**.
    
3. **Tabla de Llamadas:** Esta instrucci√≥n pasa un n√∫mero que identifica el servicio espec√≠fico solicitado (ej. leer un archivo, crear un proceso). El _kernel_ usa este n√∫mero como √≠ndice en una **tabla de llamadas al sistema** para encontrar y ejecutar la rutina interna del SO correspondiente.
    
4. **Retorno:** Una vez finalizado el servicio, el _kernel_ devuelve el control al programa de usuario, cambiando la CPU de nuevo a **modo usuario**.
## e. Defina y diferencie Programa y proceso
|Caracter√≠stica|Programa|Proceso|
|---|---|---|
|**Definici√≥n**|Una **entidad pasiva** (conjunto de instrucciones y datos) almacenada en un disco.|Una **entidad activa** (programa en ejecuci√≥n) que requiere recursos del sistema.|
|**Estado**|Est√°tico e inmutable (excepto por actualizaci√≥n).|Din√°mico, tiene un estado actual (ej. _Nuevo, Listo, Ejecuci√≥n, Espera, Terminado_).|
|**Tiempo**|Persiste en el tiempo (almacenamiento).|Temporal, existe solo mientras se ejecuta.|
|**Recursos**|No consume recursos del sistema (CPU, RAM) directamente.|**Consume recursos del sistema** y requiere un contexto de ejecuci√≥n.|
|**Ejemplo**|El archivo `.exe` o `.app` en el disco duro.|Una instancia de ese `.exe` que se ha cargado en memoria y se est√° ejecutando.|

- **Programa:** Es el c√≥digo fuente o binario. Es un concepto est√°tico.
    
- **Proceso:** Es una **instancia en ejecuci√≥n** de un programa. Es un concepto din√°mico que incluye el c√≥digo, los datos, la pila (_stack_) y el estado actual de los registros de la CPU.
## f. ¬øCu√°l es la informaci√≥n m√≠nima que el kernel debe tener sobre un proceso? ¬øEn que estructura de datos asociada almacena dicha informaci√≥n?
### Informaci√≥n M√≠nima Requerida por el Kernel

El _kernel_ necesita rastrear la siguiente **informaci√≥n m√≠nima** sobre un proceso para poder gestionarlo y reanudar su ejecuci√≥n correctamente:

1. **Identificador del Proceso (PID):** Un n√∫mero √∫nico que identifica al proceso.
    
2. **Estado del Proceso:** El estado actual del proceso (_Nuevo, Listo, Ejecuci√≥n, Espera, Terminado_).
    
3. **Contador de Programa (_Program Counter_):** La direcci√≥n de la pr√≥xima instrucci√≥n a ejecutar. **Esencial** para reanudar la ejecuci√≥n.
    
4. **Registros de la CPU:** El contenido de todos los registros de la CPU, que deben ser guardados cuando el proceso es interrumpido. **Esencial** para el cambio de contexto (_context switch_).
    
5. **Informaci√≥n de Gesti√≥n de Memoria:** Punteros o direcciones a la tabla de p√°ginas o segmentos del proceso.
    
6. **Informaci√≥n Contable/Recursos:** Tiempo de CPU usado y l√≠mites de recursos asignados.
    

### Estructura de Datos Asociada

Esta informaci√≥n se almacena en una estructura de datos dentro del _kernel_ llamada **Bloque de Control del Proceso (BCP)** o **PCB** (_Process Control Block_).

- El **PCB** es el repositorio de toda la informaci√≥n que el SO necesita para gestionar y rastrear un proceso.
    
- Existe **un PCB por cada proceso** en el sistema.
    
- El conjunto de todos los PCB es crucial para el funcionamiento del _kernel_, ya que es la principal herramienta para realizar la **planificaci√≥n** y el **cambio de contexto**.
## g. ¬øQu√© objetivos persiguen los algoritmos de planificaci√≥n (scheduling)?
Los algoritmos de planificaci√≥n (o _scheduling_) persiguen optimizar la forma en que se asigna la **Unidad Central de Procesamiento (CPU)** a los procesos listos para ejecutarse. Sus objetivos principales var√≠an seg√∫n el entorno del sistema (por lotes, interactivo, tiempo real), pero generalmente buscan:

|Objetivo|Descripci√≥n|
|---|---|
|**Maximizar la Utilizaci√≥n de la CPU**|Mantener la CPU tan ocupada como sea posible.|
|**Maximizar la Productividad (_Throughput_)**|Aumentar el n√∫mero de procesos completados por unidad de tiempo.|
|**Minimizar el Tiempo de Retorno (_Turnaround Time_)**|Reducir el tiempo total que tarda un proceso desde su llegada hasta su finalizaci√≥n.|
|**Minimizar el Tiempo de Espera**|Reducir el tiempo total que un proceso pasa en la cola de listos esperando por la CPU.|
|**Minimizar el Tiempo de Respuesta**|Reducir el tiempo que tarda el sistema en producir la primera respuesta al usuario (crucial en sistemas interactivos).|
|**Garantizar la Equidad (_Fairness_)**|Asegurar que cada proceso reciba una porci√≥n justa del tiempo de la CPU.|
## h. ¬øQu√© significa que un algoritmo de scheduling sea apropiativo o no apropiativo (Preemptive o Non-Preemptive)?
Esta distinci√≥n define c√≥mo el algoritmo maneja la **reasignaci√≥n de la CPU** una vez que un proceso ha comenzado a ejecutarse.

| Tipo de _Scheduling_                  | Significado                                                                                                                                                                                                                     | Comportamiento                                                                                                                                  |
| ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------- |
| **No Apropiativo (_Non-Preemptive_)** | Una vez que un proceso comienza a ejecutarse, **mantiene el control de la CPU** hasta que **termina** su ejecuci√≥n o pasa voluntariamente al estado de _Espera_ (ej. para una operaci√≥n de E/S).                                | No hay interrupciones forzadas por el _kernel_ basadas en tiempo o prioridad.                                                                   |
| **Apropiativo (_Preemptive_)**        | El proceso que se est√° ejecutando **puede ser interrumpido (apropiado)** en cualquier momento por el _kernel_ si un proceso de **mayor prioridad** llega o si el proceso actual ha excedido su **cuota de tiempo (_quantum_)**. | Permite una mejor **interactividad** y respuesta, ya que los procesos urgentes o nuevos no tienen que esperar a que el proceso actual finalice. |
## i. ¬øQu√© tareas realizan los siguientes m√≥dulos de planificaci√≥n?: Short,Long y Medium term scheduler
El Sistema Operativo utiliza t√≠picamente tres tipos de planificadores que operan en diferentes niveles de frecuencia y objetivos:
### i. Short Term Scheduler (Planificador a Corto Plazo)

- **Tarea:** Es el planificador m√°s frecuente. Selecciona un proceso de la cola de **procesos listos** en la memoria principal y le asigna la **CPU**.
    
- **Frecuencia:** Muy alta (se ejecuta cada pocos milisegundos).
    
- **Objetivo Principal:** Maximizar la **utilizaci√≥n de la CPU** y minimizar el **tiempo de respuesta** (controla el flujo r√°pido).
    
- **Ubicaci√≥n:** Opera entre los estados _Listo_ y _Ejecuci√≥n_.
    

### ii. Long Term Scheduler (Planificador a Largo Plazo)

- **Tarea:** Controla el **grado de multiprogramaci√≥n**. Decide qu√© trabajos o programas deben cargarse del almacenamiento secundario (disco) a la memoria principal para convertirse en **procesos listos**.
    
- **Frecuencia:** Baja (se ejecuta solo cuando un proceso termina o cuando se necesita mantener un equilibrio de la carga).
    
- **Objetivo Principal:** Seleccionar una mezcla equilibrada de procesos (E/S intensiva vs. CPU intensiva) para un uso eficiente de los recursos del sistema.
    
- **Ubicaci√≥n:** Opera entre el almacenamiento (_Job Queue_) y el estado _Nuevo/Listo_.
    

### iii. Medium Term Scheduler (Planificador a Medio Plazo)

- **Tarea:** Es responsable de la **suspensi√≥n (_swapping out_)** y **reanudaci√≥n (_swapping in_)** de procesos. Elimina temporalmente procesos de la memoria principal al almacenamiento secundario (y los devuelve m√°s tarde) para reducir el grado de multiprogramaci√≥n y liberar memoria.
    
- **Frecuencia:** Media (se ejecuta cuando el sistema est√° sobrecargado o necesita espacio de memoria).
    
- **Objetivo Principal:** Optimizar la **gesti√≥n de la memoria** y mejorar la mezcla de procesos en la memoria.
    
- **Ubicaci√≥n:** Opera entre la memoria principal (RAM) y el disco (_Suspended Queue_).
## j. ¬øQu√© tareas realiza el Dispatcher?¬øY el Loader?
### Dispatcher (_Despachador_)

El _Dispatcher_ es el m√≥dulo que cede el control de la CPU al proceso seleccionado por el planificador a corto plazo (_Short Term Scheduler_). Sus tareas incluyen:

1. **Cambio de Contexto (_Context Switch_):** Guardar el estado (registros de CPU, Contador de Programa) del proceso que se va a interrumpir y cargar el estado del nuevo proceso seleccionado.
    
2. **Cambio de Modo de Usuario:** Cambiar la CPU del modo _kernel_ al modo usuario.
    
3. **Salto a la Ubicaci√≥n Correcta:** Saltar a la direcci√≥n de memoria exacta (indicada por el Contador de Programa) donde debe reanudarse la ejecuci√≥n del nuevo proceso.
    

El _Dispatcher_ debe ser lo m√°s r√°pido posible, ya que se ejecuta en cada cambio de proceso (_Context Switch_).

### Loader (_Cargador_)

El _Loader_ es el componente del sistema operativo que se encarga de:

1. **Cargar el Programa:** Llevar el c√≥digo y los datos de un programa desde el almacenamiento secundario (disco) a la **memoria principal (RAM)**.
    
2. **Preparaci√≥n para la Ejecuci√≥n:** Inicializar los registros de la CPU y las estructuras de gesti√≥n de memoria del proceso, preparando el entorno para que el programa pueda comenzar su ejecuci√≥n como un proceso.
## k. ¬øQu√© significa que un proceso sea "CPU Bound" y "I/O Bound"?
La diferencia describe el tipo de recurso que m√°s consume o limita la velocidad de un proceso:

|Tipo de Proceso|Significado|Caracter√≠sticas|Ejemplo|
|---|---|---|---|
|**CPU Bound** (Limitado por CPU)|Pasa la mayor parte de su tiempo **ejecutando c√°lculos** y realizando muy pocas operaciones de Entrada/Salida (E/S).|Su velocidad se limita por la **velocidad de la CPU**. Realizan r√°fagas largas de uso de CPU.|Programas de c√°lculo cient√≠fico, simulaciones complejas, renderizado de video, compiladores.|
|**I/O Bound** (Limitado por E/S)|Pasa la mayor parte de su tiempo **esperando** a que se completen las operaciones de Entrada/Salida.|Su velocidad se limita por la **velocidad de los dispositivos de E/S**. Realizan r√°fagas muy cortas de uso de CPU.|Editores de texto, navegadores web, servidores de bases de datos que leen/escriben constantemente en disco.|

El _Scheduler_ busca equilibrar estos dos tipos para maximizar la utilizaci√≥n de la CPU (mientras los procesos _I/O Bound_ esperan, los _CPU Bound_ pueden ejecutar).

## l. ¬øCu√°les son los estados posibles por los que puede atravesar un proceso? ¬øQu√© representa que un proceso se encuentre en los estados enumerados? Utilizando un diagrama explique las transiciones entre los estados.
Los procesos atraviesan una serie de estados que representan su actividad actual dentro del Sistema Operativo.

### Estados Posibles

1. **Nuevo (_New_):** El proceso est√° siendo creado.
    
    - **Representa:** El programa ha sido invocado y el SO est√° estableciendo sus estructuras de datos (PCB).
        
2. **Listo (_Ready_):** El proceso est√° esperando a que se le asigne la CPU.
    
    - **Representa:** El proceso reside en la memoria principal, tiene todos los recursos que necesita, y puede ejecutar su siguiente instrucci√≥n inmediatamente si la CPU estuviera disponible.
        
3. **Ejecuci√≥n (_Running_):** El proceso est√° ejecutando instrucciones en la CPU.
    
    - **Representa:** Se est√°n realizando las operaciones propias del c√≥digo del programa. Solo puede haber un proceso en este estado por cada n√∫cleo de CPU.
        
4. **Espera (_Waiting_):** El proceso est√° esperando a que ocurra alg√∫n evento (generalmente la finalizaci√≥n de una operaci√≥n de E/S o la recepci√≥n de una se√±al).
    
    - **Representa:** El proceso no puede continuar, incluso si la CPU estuviera libre, hasta que se complete la operaci√≥n externa solicitada.
        
5. **Terminado (_Terminated_):** El proceso ha finalizado su ejecuci√≥n.
    
    - **Representa:** El SO est√° liberando los recursos del proceso (PCB, memoria) que ha completado su tarea.
        

### Diagrama de Transici√≥n de Estados

Las transiciones entre estados ocurren por eventos controlados por el SO:

- **1. Admisi√≥n:** El _Long Term Scheduler_ mueve el proceso de **Nuevo** a **Listo**.
    
- **2. Despacho (_Dispatch_):** El _Dispatcher_ mueve el proceso de **Listo** a **Ejecuci√≥n** (asignaci√≥n de CPU).
    
- **3. Interrupci√≥n/Expiraci√≥n (_Interrupt_):** Si se acaba el _quantum_ de tiempo o llega un proceso de mayor prioridad, el SO mueve el proceso de **Ejecuci√≥n** a **Listo** (Apropiaci√≥n).
    
- **4. Espera de E/S:** El proceso solicita una E/S o espera un evento, movi√©ndose de **Ejecuci√≥n** a **Espera**.
    
- **5. Fin de E/S:** El evento o la E/S que el proceso estaba esperando termina, movi√©ndolo de **Espera** a **Listo**.
    
- **6. Salida (_Exit_):** El proceso termina su ejecuci√≥n de forma normal o anormal, movi√©ndose de **Ejecuci√≥n** a **Terminado**.
## m. ¬øCu√°les de los schedulers mencionados anteriormente se encargan de las transiciones entre los estados enumerados?
Los diferentes planificadores se encargan de gestionar las siguientes transiciones de estado:

| Planificador (_Scheduler_)      | Transiciones que Gestiona                                                      | Estados Involucrados                           |
| ------------------------------- | ------------------------------------------------------------------------------ | ---------------------------------------------- |
| **Long Term Scheduler** (LTS)   | Admisi√≥n (cargar un trabajo).                                                  | **Nuevo** ‚Üí **Listo**                          |
| **Short Term Scheduler** (STS)  | Despacho (asignar la CPU).                                                     | **Listo** ‚Üí **Ejecuci√≥n**                      |
| **Medium Term Scheduler** (MTS) | Suspensi√≥n/Reanudaci√≥n (_Swapping_).                                           | **Listo** ‚áå **Suspendido/Espera** (Libera RAM) |
| **Dispatcher**                  | Cambios de estado por Expiraci√≥n de _Quantum_ o Solicitud/Finalizaci√≥n de E/S. | **Ejecuci√≥n** ‚Üí **Listo** (Apropiaci√≥n)        |
| **Kernel (M√≥dulos de E/S)**     | Finalizaci√≥n de E/S/Evento.                                                    | **Espera** ‚Üí **Listo**                         |
| **Kernel**                      | Salida.                                                                        | **Ejecuci√≥n** ‚Üí **Terminado**                  |
## n. Defina Tiempo de retorno (TR) y Tiempo de espera (TE) para un proceso.
Para un proceso individual:

- **Tiempo de Retorno (TR) o _Turnaround Time_:** Es el intervalo total de tiempo transcurrido desde que un proceso **llega** al sistema hasta que **termina** su ejecuci√≥n. Mide la latencia total del proceso, incluyendo su tiempo de ejecuci√≥n y todos los tiempos de espera.
    
    TR=Tiempo¬†de¬†FinalizacioÀän‚àíTiempo¬†de¬†Llegada
    
- **Tiempo de Espera (TE) o _Waiting Time_:** Es la cantidad total de tiempo que un proceso pasa en la cola de **Listo**, esperando ser asignado a la CPU. No incluye el tiempo que pasa en el estado _Espera_ (bloqueado por E/S).
    
    TE=Tiempo¬†de¬†Retorno‚àíTiempo¬†de¬†EjecucioÀän¬†de¬†CPU

## o. Defina Tiempo Promedio de Retorno (TPR) y Tiempo promedio de espera (TPE) para un lote de procesos.
Estas m√©tricas se aplican a un **conjunto o lote de n procesos** y se utilizan para evaluar la eficiencia global de un algoritmo de planificaci√≥n.

![[Pasted image 20250925170034.png]]
## p. Defina tiempo de respuesta.
- **Tiempo de Respuesta (_Response Time_):** Es el tiempo transcurrido desde que un proceso **llega** al sistema hasta que **produce su primera respuesta** o comienza su primera ejecuci√≥n.
    

Esta m√©trica es crucial para los **sistemas interactivos** (como los sistemas de escritorio), ya que mide la rapidez con la que el usuario percibe que el sistema est√° respondiendo a su solicitud.

Tiempo¬†de¬†Respuesta=Tiempo¬†de¬†la¬†Primera¬†EjecucioÀän‚àíTiempo¬†de¬†Llegada

## 2. Para los siguientes algoritmos de scheduling:

‚û¢‚Äã FCFS (First Come First Served)

‚û¢‚Äã SJF (Shortest Job First)

‚û¢‚Äã Round Robin

‚û¢‚Äã Prioridades
## a.‚Äã Explique su funcionamiento mediante un ejemplo.
Supongamos 3 procesos: **P1** (r√°faga de 24 ms, llegada en 0 ms), **P2** (r√°faga de 3 ms, llegada en 0 ms) y **P3** (r√°faga de 3 ms, llegada en 0 ms).

| Algoritmo                          | Funcionamiento                                                                                                                                                                                                                                               | Ejemplo (Orden de Ejecuci√≥n)                                                                                                                                                       |
| ---------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **FCFS** (First Come First Served) | **No expropiativo**. El proceso que llega primero es el primero en ser ejecutado. Se usa una cola **FIFO**.                                                                                                                                                  | Si llegan en orden **P1, P2, P3**: Se ejecuta P1 (0-24), luego P2 (24-27), luego P3 (27-30).                                                                                       |
| **SJF** (Shortest Job First)       | **Puede ser expropiativo o no expropiativo**. Se ejecuta el proceso con la r√°faga de CPU **m√°s corta**. Minimiza el tiempo de espera promedio.                                                                                                               | Si todos llegan en 0 ms con r√°fagas 24, 3, 3: Se ejecutar√≠an **P2, P3, P1** (o P3, P2, P1) debido a que sus r√°fagas son las m√°s cortas.                                            |
| **Round Robin** (RR)               | **Expropiativo**. Cada proceso recibe un peque√±o segmento de tiempo de CPU, llamado **Quantum** (q). Si el proceso no termina en ese tiempo, es interrumpido y se coloca al final de la cola de listos, esperando su siguiente turno. Usa una cola circular. | Con q=4¬†ms y r√°fagas 24, 3, 3: Se rotan los procesos. P1 usa 4 ms, P2 usa 3 ms (termina), P3 usa 3 ms (termina), P1 usa 4 ms, y as√≠ sucesivamente hasta que P1 complete sus 24 ms. |
| **Prioridades**                    | **Puede ser expropiativo o no expropiativo**. Se asigna un valor de **prioridad** a cada proceso. El planificador elige el proceso con la prioridad m√°s alta para ejecutar.                                                                                  | Si P1 (Prioridad 4), P2 (Prioridad 1), P3 (Prioridad 5). (Asumiendo que 1 es la m√°s alta): Se ejecutar√≠a **P2, P1, P3**.                                                           |
## b.‚Äã ¬øAlguno de ellos cuentan con par√°metros para su funcionamiento? Identifique y enunciarlos
Solo dos de los algoritmos listados cuentan con un par√°metro clave para su funcionamiento:

1. **Round Robin (RR):**
    
    - **Quantum de tiempo (q):** Es la unidad de tiempo (ej. milisegundos o _ticks_) que se le asigna a cada proceso para usar la CPU antes de ser forzado a ceder el turno al siguiente proceso en la cola.
        
2. **Prioridades:**
    
    - **Valor de Prioridad:** Es el valor num√©rico o cualitativo asignado a cada proceso, que determina su orden de ejecuci√≥n. Un criterio com√∫n es que un n√∫mero bajo indica una prioridad alta (o viceversa).
        
    - **(Opcional) Tasa de Envejecimiento (Aging Rate):** Este no es un par√°metro directo del algoritmo simple, sino un mecanismo implementado para evitar la inanici√≥n. Consiste en aumentar din√°micamente la prioridad de los procesos que han esperado mucho tiempo.
        

**FCFS** y **SJF** (en su forma simple y no expropiativa) no requieren par√°metros adicionales m√°s all√° del tiempo de llegada y el tiempo de r√°faga de CPU del proceso, respectivamente.
## c.‚Äã Cual es el m√°s adecuado seg√∫n los tipos de procesos y/o SO.

|Algoritmo|Tipo de Proceso/SO M√°s Adecuado|Raz√≥n Principal|
|---|---|---|
|**FCFS**|Sistemas de **Procesamiento por Lotes (Batch)**.|Su simplicidad y baja sobrecarga administrativa lo hacen √∫til donde la respuesta r√°pida no es cr√≠tica. Sin embargo, no es adecuado para sistemas interactivos.|
|**SJF**|Sistemas de **Prop√≥sito General** o **Batch** (si se puede estimar la r√°faga).|Es te√≥ricamente √≥ptimo para minimizar el **tiempo promedio de espera** y el **tiempo promedio de retorno**. La versi√≥n expropiativa (**SRTF**) es mejor para entornos donde el proceso corto debe terminar r√°pido.|
|**Round Robin**|Sistemas de **Tiempo Compartido** o **Interactivos** (multiusuario/multitarea).|Su equidad y garant√≠a de una porci√≥n de CPU para cada proceso resultan en un **buen tiempo de respuesta** para el usuario. Es el pilar de la planificaci√≥n en SO modernos.|
|**Prioridades**|Sistemas de **Tiempo Real** o donde las tareas tienen **criticidad** variable.|Permite garantizar que los procesos vitales del sistema (alta prioridad) o los procesos sensibles al tiempo (tiempo real) sean ejecutados antes que los menos cr√≠ticos.|
## d.‚Äã Cite ventajas y desventajas de su uso.

|Algoritmo|Ventajas|Desventajas|
|---|---|---|
|**FCFS**|Muy **simple** de implementar. **Baja sobrecarga** de gesti√≥n (no requiere interrupciones de temporizador).|**Pobre rendimiento** en sistemas interactivos. Sufre del **efecto convoy** (un proceso largo bloquea a todos los dem√°s).|
|**SJF**|**√ìptimo** para minimizar el **tiempo de espera promedio** y el **tiempo de retorno promedio**.|**Dif√≠cil de implementar** porque requiere **predecir la duraci√≥n de la pr√≥xima r√°faga** de CPU. Puede causar **inanici√≥n** (los procesos largos nunca se ejecutan si hay un flujo constante de procesos cortos).|
|**Round Robin**|**Equitativo** (fairness), garantizando el acceso a la CPU. **Buen tiempo de respuesta** en sistemas interactivos. Previene la inanici√≥n.|Introduce **sobrecarga por cambios de contexto** (si el quantum es muy peque√±o). El **tiempo de retorno promedio** puede ser alto para procesos largos. El rendimiento depende cr√≠ticamente de la elecci√≥n del **quantum**.|
|**Prioridades**|Permite dar un **trato preferencial** a procesos cr√≠ticos o sensibles al tiempo. Flexible para modelar otros algoritmos (SJF es un caso de prioridad).|El principal problema es la **inanici√≥n** (**starvation**) para los procesos de baja prioridad. Se requiere un mecanismo como el **envejecimiento (aging)** para mitigarla.|
## 3.
![[Pasted image 20250928143020.png]]
### i.
![[Pasted image 20250928143053.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 6   | 0   |
| 2    | 21  | 14  |
| 3    | 33  | 21  |
| 4    | 37  | 33  |
| 5    | 46  | 37  |
| PROM |     |     |
FORMULA te = tr - CPU
### ii.
![[Pasted image 20250928143208.png]]
sumo 1 a cada (contando el 0)???

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 10  | 3   |
| 2    | 46  | 31  |
| 3    | 31  | 19  |
| 4    | 4   | 0   |
| 5    | 19  | 10  |
| PROM |     |     |
### iii.
![[Pasted image 20250928143310.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 22  |     |
| 2    |     |     |
| 3    |     |     |
| 4    |     |     |
| 5    |     |     |
| PROM |     |     |

## 4. Dado el siguiente lote de procesos

| job | LLegada | Unidades de CPU |
| --- | ------- | --------------- |
| 1   | 0       | 4               |
| 2   | 2       | 6               |
| 3   | 3       | 4               |
| 4   | 6       | 5               |
| 5   | 8       | 2               |
### FCFS
![[Pasted image 20251006150849.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 4   | 0   |
| 2    | 8   | 2   |
| 3    | 11  | 7   |
| 4    | 13  | 8   |
| 5    | 13  | 11  |
| PROM | 9,8 | 5,6 |

### SJF
![[Pasted image 20251006151104.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 4   | 0   |
| 2    | 19  | 13  |
| 3    | 5   | 1   |
| 4    | 9   | 4   |
| 5    | 2   | 0   |
| PROM | 7,8 | 3,6 |

### RR q=1
![[Pasted image 20251006151130.png]]

| P    | TR   | TE  |
| ---- | ---- | --- |
| 1    | 7    | 0   |
| 2    | 17   | 11  |
| 3    | 14   | 10  |
| 4    | 15   | 10  |
| 5    | 8    | 6   |
| PROM | 12,2 | 7,4 |

### RR q=6
![[Pasted image 20251006151207.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 4   | 0   |
| 2    | 8   | 2   |
| 3    | 11  | 7   |
| 4    | 13  | 8   |
| 5    | 13  | 11  |
| PROM | 9,8 | 5,6 |
### c. En base a los tiempos calculados, compare los diferentes algoritmos

### d. En el algoritmo RR, que conclusi√≥n se puede sacar con respecto al valor del quantum?

### e. ¬øPara el algoritmo Round Robin, en qu√© casos utilizar√° un valor dequantum alto y qu√© ventajas y desventajas obtendr√≠a?
### üí° Si se usa un **quantum alto**:

Esto significa que cada proceso puede ejecutar durante m√°s tiempo antes de ser interrumpido.

#### ‚úÖ **Ventajas:**

1. **Menos cambios de contexto** ‚Üí se reduce la sobrecarga del sistema (menos tiempo perdido cambiando entre procesos).
    
2. **Mejor rendimiento para procesos largos** ‚Üí si las tareas suelen ser pesadas (por ejemplo, c√°lculos o simulaciones), terminan antes de ser interrumpidas.
    
3. **M√°s parecido a un sistema por lotes (batch)** ‚Üí puede mejorar el throughput (cantidad de trabajo completado por unidad de tiempo) si las tareas no son interactivas.
    

#### ‚ùå **Desventajas:**

1. **Menor capacidad de respuesta** ‚Üí los procesos cortos o interactivos (como los que esperan input del usuario) pueden tardar mucho en volver a ejecutar.
    
2. **Inequidad percibida** ‚Üí un proceso que justo termine antes de que se acabe el quantum puede hacer esperar a los dem√°s demasiado tiempo.
    
3. **Se pierde el esp√≠ritu del Round Robin** ‚Üí con un quantum demasiado alto, se comporta casi como un planificador FCFS (_First Come, First Served_).
    

---
### ‚öñÔ∏è **Resumen visual:**

|Quantum|Ventajas|Desventajas|Tipo de sistema recomendado|
|---|---|---|---|
|**Bajo**|Alta respuesta, justo con procesos cortos|Mucho cambio de contexto|Sistemas interactivos o en tiempo compartido|
|**Alto**|Menos overhead, m√°s rendimiento para procesos largos|Menor interactividad|Sistemas batch o de procesamiento intensivo|
## 5. Una variante al algoritmo SJF es el algoritmo SJF apropiativo o SRTF (Shortest Remaining Time First):
### a.‚Äã Realice el diagrama de Gantt para este algoritmo seg√∫n el lote de trabajos del ejercicio 5
![[Pasted image 20251006162412.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    | 4   | 0   |
| 2    | 19  | 13  |
| 3    | 5   | 1   |
| 4    | 4   | 9   |
| 5    | 2   | 0   |
| PROM | 6,8 | 4,6 |

### b.‚Äã ¬øNota alguna ventaja frente a otros algoritmos?

Esto significa que **si llega un nuevo proceso con un tiempo de ejecuci√≥n restante menor** que el del proceso actual, **el CPU se le cede inmediatamente** a ese nuevo proceso.

---

### ‚úÖ **Ventajas del SRTF**

1. **Tiempo de espera promedio m√≠nimo**  
    Es el algoritmo √≥ptimo en cuanto a **minimizar el tiempo de espera promedio**, porque siempre se elige el proceso que terminar√° m√°s r√°pido.
    
    > Ejemplo: si llega un proceso corto mientras otro largo est√° ejecutando, el corto no queda ‚Äúbloqueado‚Äù mucho tiempo.
    
2. **Mejor tiempo de respuesta para procesos cortos**  
    Los procesos peque√±os o interactivos reciben atenci√≥n casi inmediata, lo que mejora la **interactividad del sistema**.
    
3. **Uso eficiente del procesador**  
    El CPU est√° casi siempre ejecutando el proceso m√°s conveniente (el que liberar√° antes el recurso), maximizando as√≠ la productividad global.
    

---

### ‚ùå **Desventajas (para contrastar)**

Aunque no lo ped√≠s, vale la pena mencionarlas brevemente:

- Requiere **conocer o estimar la duraci√≥n de los procesos**, lo cual no siempre es posible.
    
- Puede provocar **injusticia o inanici√≥n (starvation)**: procesos largos pueden esperar mucho si siguen llegando procesos cortos.
    
- Tiene **mayor sobrecarga** que el SJF no apropiativo, porque implica m√°s decisiones de cambio de proceso.
    

---

### üß© **Resumen**

|Caracter√≠stica|SJF no apropiativo|**SRTF (apropiativo)**|
|---|---|---|
|Tipo|No interrumpe al proceso en ejecuci√≥n|Puede interrumpir si llega uno m√°s corto|
|Tiempo de espera promedio|Bajo|üîπ **M√≠nimo posible**|
|Tiempo de respuesta|Bueno|üîπ **Excelente para procesos cortos**|
|Sobrecarga|Menor|Mayor|
|Posible inanici√≥n|Moderada|M√°s probable|
## 6. Suponga que se agregan las siguientes prioridades al lote de procesos delejercicio 5, donde un menor n√∫mero indica mayor prioridad:

| job | Prioridad | LLegada | Unidades de CPU |
| --- | --------- | ------- | --------------- |
| 1   | 3         | 0       | 4               |
| 2   | 4         | 2       | 6               |
| 3   | 2         | 3       | 4               |
| 4   | 1         | 6       | 5               |
| 5   | 2         | 8       | 2               |

### Apropiativo
![[Pasted image 20251007175016.png]]

| P    | TR   | TE  |
| ---- | ---- | --- |
| 1    | 15   | 11  |
| 2    | 19   | 13  |
| 3    | 9    | 5   |
| 4    | 5    | 0   |
| 5    | 6    | 4   |
| PROM | 10,8 | 6,6 |


### No Apropiativa
![[Pasted image 20251007175027.png]]

| P    | TR  | TE  |
| ---- | --- | --- |
| 1    |     |     |
| 2    |     |     |
| 3    |     |     |
| 4    |     |     |
| 5    |     |     |
| PROM |     |     |
### c.‚Äã ¬øNota alguna ventaja frente a otros algoritmos? ¬øBajo qu√© circunstancias lo utilizar√≠a y ante qu√© situaciones considera que la implementaci√≥n de prioridades podr√≠a no ser de mayor relevancia?
**Ventajas frente a otros algoritmos:**

- Permite **dar preferencia a procesos cr√≠ticos o m√°s importantes**, algo que FCFS o SJF no consideran.
    
- Puede **mejorar el tiempo de respuesta de tareas urgentes**, garantizando que trabajos del sistema (por ejemplo, interrupciones o procesos interactivos) reciban CPU antes que los procesos de baja prioridad.
    
- En su versi√≥n **apropiativa**, puede reaccionar din√°micamente cuando llega un proceso de mayor prioridad, interrumpiendo otro en ejecuci√≥n (√∫til en sistemas de tiempo real o interactivos).
    

**Cu√°ndo lo usar√≠a:**

- En **sistemas de tiempo real** o **multitarea interactiva**, donde algunas tareas deben ejecutarse antes que otras (por ejemplo, control de dispositivos, atenci√≥n de eventos, o procesos del kernel).
    
- Cuando se necesita **controlar la pol√≠tica de planificaci√≥n seg√∫n la importancia o urgencia del proceso**.
    
- En entornos donde se puede **asignar prioridad seg√∫n tipo de tarea o usuario** (por ejemplo, prioridad m√°s alta a procesos del sistema y menor a procesos de usuario).
    

**Cu√°ndo las prioridades podr√≠an no ser relevantes o incluso problem√°ticas:**

- En sistemas donde **todos los procesos son equivalentes** o tienen **tiempos de CPU similares**, la prioridad no aporta beneficios reales frente a algoritmos m√°s simples (como Round Robin o FCFS).
    
- Puede provocar **inanici√≥n (starvation)**: los procesos de baja prioridad podr√≠an nunca ejecutarse si siguen llegando procesos de alta prioridad.
    
- Si las prioridades no est√°n bien definidas o son asignadas arbitrariamente, el algoritmo pierde sentido y puede generar injusticia o ineficiencia.
    

---

üëâ En resumen:

> El algoritmo por prioridades es ventajoso cuando hay distintos niveles de urgencia o criticidad en los procesos, pero pierde relevancia en sistemas homog√©neos o donde se busca equidad.

## 7. Inanici√≥n
### 7.a. ¬øQu√© significa?

La **Inanici√≥n (Starvation)** ocurre cuando un proceso (o un hilo) est√° listo para ejecutarse, pero es **permanentemente postergado** e impedido de acceder a la CPU (u otro recurso vital) debido a un sesgo en el algoritmo de planificaci√≥n.

En esencia, un proceso con baja prioridad puede esperar indefinidamente mientras procesos de mayor prioridad contin√∫an llegando y acaparando la CPU. El proceso nunca muere de forma natural (por finalizaci√≥n), sino que "muere de hambre" al no recibir servicio.

---

### 7.b. ¬øCu√°l/es de los algoritmos vistos puede provocarla?

Los dos principales algoritmos que pueden causar inanici√≥n son:

1. **Planificaci√≥n por Prioridades (Priority Scheduling):**
    
    - **Causa:** Un proceso de **baja prioridad** podr√≠a esperar indefinidamente si continuamente llegan o se crean nuevos procesos de **alta prioridad**.
        
2. **Shortest Job First (SJF) y Shortest Remaining Time First (SRTF):**
    
    - **Causa:** Un proceso con un **tiempo de r√°faga (burst time) muy largo** podr√≠a nunca ser seleccionado si hay un flujo constante de procesos con tiempos de r√°faga m√°s cortos (o tiempos restantes m√°s cortos).
        

---

### 7.c. ¬øExiste alguna t√©cnica que evite la inanici√≥n para el/los algoritmos mencionados en el inciso b?

S√≠, la principal y m√°s efectiva t√©cnica para combatir la inanici√≥n, especialmente en la Planificaci√≥n por Prioridades, es el **Envejecimiento (Aging)**. üë¥

#### Envejecimiento (Aging)

- **T√©cnica:** Es un m√©todo que **incrementa gradualmente la prioridad** de los procesos que han estado esperando en la cola durante un tiempo excesivo.
    
- **Mecanismo:** Cuanto m√°s tiempo pase un proceso sin recibir servicio, mayor ser√° su prioridad.
    
- **Resultado:** Esto garantiza que, eventualmente, incluso el proceso con la prioridad inicial m√°s baja alcanzar√° una prioridad lo suficientemente alta como para ser seleccionado y ejecutado, evitando as√≠ la inanici√≥n.
    

Esta t√©cnica tambi√©n puede aplicarse al algoritmo **SJF/SRTF** de forma impl√≠cita o expl√≠cita. Un proceso muy largo que espera mucho tiempo tiene su prioridad aumentada, asegurando que su gran tiempo de r√°faga se vea compensado por su elevada prioridad al final.
## 8. Agregarle al ejercicio 5 las siguientes operaciones
### FCFS

| job | LLegada | Unidades de CPU | I/0 (Recurso, instante, duraci√≥n) | 0   | 1   | 2   | 3   | 4   | 5   | 6   | 7   | 8   | 9   | 10  | 11  |
| --- | ------- | --------------- | --------------------------------- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| 1   | 0       | 4               | (R1, 2, 1)                        | >1  | 2   | R1  |     |     |     | 3   | 4<  |     |     |     |     |
| 2   | 2       | 6               | (R2, 3, 1) (R2, 5, 2)             |     |     | >1  | 2   | 3   | R2  |     |     |     |     |     |     |
| 3   | 3       | 4               |                                   |     |     |     | >   |     |     |     |     | 1   | 2   | 3   | 4<  |
| 4   | 6       | 5               | (R3, 1, 2) (R3, 3, 1)             |     |     |     |     |     |     | >   |     |     |     |     |     |
| 5   | 8       | 2               |                                   |     |     |     |     |     |     |     |     | >   |     |     |     |
|     |         |                 |                                   |     |     |     |     |     |     |     |     |     |     |     |     |
|     | Queue   | 1               | ~~2~~                             | 3   | 4   | 5   |     |     |     |     |     |     |     |     |     |
|     | QueueR1 | 1               |                                   |     |     |     |     |     |     |     |     |     |     |     |     |
|     | QueueR2 |                 |                                   |     |     |     |     |     |     |     |     |     |     |     |     |
|     | QueueR3 |                 |                                   |     |     |     |     |     |     |     |     |     |     |     |     |
### FCFS 


---

## 19. Dados los siguientes programas en pseudo c√≥digo que simulan la utilizaci√≥n de llamadas al sistema para crear procesos en Unix/linux, indicar qu√© mensajes se imprimir√°n en pantalla (sin importar el orden en el que saldr√≠an)

```
a.‚Äã Caso 1

printf(‚Äúhola‚Äù)
x = fork()
if x < 1 {
	execv(‚Äúls‚Äù)
	printf(‚Äúmundo‚Äù)
	exit(0)
}
exit(0)
```
R: 
Hola!
imprime resultado de ls

```
b.‚Äã Caso 2
	printf(‚Äúhola‚Äù)
	x = fork()
	if x < 1 {
		execv(‚Äúps‚Äù)
		printf(‚Äúmundo‚Äù)
		exit(0)
	}
	execv(‚Äúls‚Äù)
	printf(‚Äúfin‚Äù)
	exit(0)
```
R:
Hola
imprime resultado de ps (lista procesos)
imprime resultados de ls (lista directorios)
```
Caso 3
	printf(‚ÄúAnda a rendir el Primer Parcial de Promo!‚Äù)
	newpid = fork()
	if newpid == 0 {
		printf(‚ÄúEstoy comenzando el Examen‚Äù)
		execv(‚Äúps‚Äù)
		printf(‚ÄúTermine el Examen‚Äù)
	}
	printf(‚Äú¬øComo te fue?‚Äù)
	exit(0)
	printf(‚ÄúAhora anda a descansar‚Äù)
```
R: 
Anda a rendir el primer parcial de promo!
Estoy comenzando el examen
resultado del comando ps
¬øC√≥mo te fue?

---
## 20. Dado el siguiente programa en C, analice su objetivo sin necesidad de ejecutarlo.
```c
#include <stdio.h>
#include <sys/types.h>
#include <unistd.h>
int main ( void ) {
	int c ;
	pid_t pid ;
	printf( " Comienzo . : \ n " ) ;
	for ( c = 0 ; c < 3 ; c++ ) {
		pid = fork ( ) ;
	}
	printf ( " Proceso \n " ) ;
	return 0 ;
}
```
RA: Este programa realiza 3 iteraciones, en cada una se ejecuta un fork, duplicando el proceso actual.
Por lo tanto el n√∫mero de procesos se multiplica por 2 en cada iteraci√≥n.
2 al cubo, quedan 8 l√≠neas con la palabra proceso

RB: si, cada "proceso" proviene de un proceso diferente que llega a esa ejecuci√≥n

---
## 21. Modifiquemos el programa anterior. Ahora adem√°s de un mensaje, vamos a a√±adir una variable y antes de finalizar vamos a mostrar el valor de la misma.
```c
#include <stdio.h>
#include <sys/types.h>
#include <unistd.h>
int main ( void ) {
	int c ;
	pid_t pid ;
	int p = 0;
	printf( " Comienzo . : \ n " ) ;
	for ( c = 0 ; c < 3 ; c++ ) {
		pid = fork ( ) ;
	}
	p++;
	printf ( " Proceso %d\n ",p ) ;
	return 0 ;
}
```
RA: ¬øQu√© valores se imprimir√°n en consola?
El for crea 3 forks, al final se tienen 8 procesos.
Como la variable p se inicio antes del fork, todos heredan ese valor, entonces siempre imprime "Proceso 1".

RB: ¬øTodas las l√≠neas tendr√°n el mismo valor o algunas l√≠neas tendr√°n valores distintos?
Todas las l√≠neas tienen el mismo valor 1.

RC: ¬øCu√°l es el valor (o valores) que aparece?. Compile y ejecute el programa y pruebe si su respuesta es correcta.
Proceso1 X 8.

RD: ¬øRealice modificaciones al programa, por ejemplo: modifique el valor del bucle for, cambie el lugar d√≥nde se incrementa la variable p, y compruebe los nuevos resultados?
Si se coloca el incremento de p, dentro del bucle for, despu√©s del fork, ahora si se imprimiria proceso con su n√∫mero correspondiente.

---
## 22. ¬øQu√© es la MMU y qu√© funciones cumple?
La **MMU** es la encargada de que cada proceso crea tener su propia memoria aislada y segura, traduciendo las direcciones que usa el programa en direcciones reales de la RAM y gestionando la protecci√≥n y eficiencia del sistema de memoria. La MMU implementa mecanismos como paginaci√≥n y segmentaci√≥n!

---
## 23. ¬øQu√© representa el espacio de direcciones de un proceso?
El **espacio de direcciones** de un proceso representa **el conjunto de direcciones de memoria que ese proceso puede usar**.  
En otras palabras:

> Es **la visi√≥n que un proceso tiene de la memoria**, como si fuera toda suya, aunque en realidad el sistema operativo y la MMU la est√©n gestionando y aislando del resto.

---

### üîç **Detalles importantes**

1. **Cada proceso tiene su propio espacio de direcciones virtuales.**
    
    - Eso significa que dos procesos pueden usar, por ejemplo, la direcci√≥n `0x8048000`, pero en realidad apuntan a **lugares f√≠sicos distintos** en la RAM.
        
    - Esto lo logra la **MMU** mediante la **traducci√≥n de direcciones virtuales a f√≠sicas**.
        
2. **El espacio de direcciones es virtual.**
    
    - Los programas no trabajan con direcciones f√≠sicas reales, sino con **direcciones virtuales** que son mapeadas din√°micamente por el sistema operativo.
        
3. **Permite aislamiento y seguridad.**
    
    - Un proceso no puede acceder (salvo excepciones controladas) a la memoria de otro.
        
    - As√≠ se evita que un error o ataque afecte a otros procesos o al kernel.
        

---

### üß© **Estructura t√≠pica del espacio de direcciones**

En un sistema t√≠pico (por ejemplo Linux de 32 bits), el espacio de direcciones de un proceso se organiza m√°s o menos as√≠:
```
+------------------------+  ‚Üê Direcciones altas
|   Kernel (SO)          |
+------------------------+
|   Pila (Stack)         | ‚Üê Crece hacia abajo
+------------------------+
|   Heap (malloc, new)   | ‚Üê Crece hacia arriba
+------------------------+
|   Datos est√°ticos      | ‚Üê Variables globales e inicializadas
+------------------------+
|   C√≥digo (Text)        | ‚Üê Instrucciones del programa
+------------------------+  ‚Üê Direcci√≥n 0

```
- **C√≥digo (text segment):** contiene las instrucciones del programa.
    
- **Datos (data segment):** variables globales y est√°ticas.
    
- **Heap:** memoria din√°mica (malloc, new, etc.).
    
- **Stack:** pila de ejecuci√≥n (funciones, variables locales).
### üß≠ **En resumen**

| Concepto   | Descripci√≥n                                                  |
| ---------- | ------------------------------------------------------------ |
| Definici√≥n | Conjunto de direcciones de memoria que un proceso puede usar |
| Tipo       | Virtual (no corresponde directamente a direcciones f√≠sicas)  |
| Prop√≥sito  | Aislar procesos y simplificar la gesti√≥n de memoria          |
| Estructura | C√≥digo, datos, heap, pila, y espacio del kernel              |

---
## 24. Explique y relacione los siguientes conceptos:
### Direcci√≥n l√≥gica o virtual
- Es la **direcci√≥n de memoria que genera la CPU** cuando un programa se ejecuta.
    
- Tambi√©n se la llama **direcci√≥n virtual**, porque **no corresponde directamente a una posici√≥n f√≠sica en la RAM**.
    
- Cada proceso trabaja con su propio conjunto de direcciones l√≥gicas (su **espacio de direcciones**), lo que le da la **ilusi√≥n de tener toda la memoria para s√≠ mismo**.

>[!tip] Ejemplo
> El proceso A accede a la direcci√≥n virtual `0x1000`.  
> El proceso B tambi√©n puede usar `0x1000`, pero en realidad apuntan a diferentes zonas f√≠sicas de la RAM.

### Direcci√≥n f√≠sica
- Es la **direcci√≥n real en la memoria RAM** donde se almacenan los datos o instrucciones.
    
- La memoria f√≠sica es √∫nica para todo el sistema, y el sistema operativo se encarga de **asignar partes de ella a cada proceso**.
    
- Las direcciones f√≠sicas son las que la **MMU finalmente utiliza para acceder a la RAM**.
>[!tip] Ejemplo
>La direcci√≥n virtual `0x1000` del proceso A puede corresponder a la direcci√≥n f√≠sica `0xABC000` en RAM.

---
## 25. 
En la t√©cnica de Particiones M√∫ltiples, la memoria es dividida en varias particiones y los espacios de direcciones de los procesos son ubicados en estas, siempre que el
tama√±o del mismo sea menor o igual que el tama√±o de la partici√≥n.
Al trabajar con particiones se pueden considerar 2 m√©todos (independientes
entre s√≠):
	‚Äã Particiones Fijas
	‚Äã Particiones Din√°micas

### a.‚Äã Explique c√≥mo trabajan estos 2 m√©todos. Cite diferencias, ventajas y desventajas.

#### Particiones Fijas
En el m√©todo de **particiones fijas**, la memoria principal se divide en varias particiones de **tama√±os predefinidos y fijos** al iniciar el sistema operativo. Estas particiones no cambian de tama√±o. A cada proceso se le asigna la primera partici√≥n disponible que sea lo suficientemente grande para alojarlo.

- **Ventajas:**
    
    - **Simplicidad:** Su implementaci√≥n es relativamente sencilla.
        
    - **Baja sobrecarga:** No requiere mucha sobrecarga para su gesti√≥n.
        
- **Desventajas:**
    
    - **Fragmentaci√≥n interna:** Un proceso peque√±o puede ser asignado a una partici√≥n grande, dejando espacio sin usar dentro de esa partici√≥n. Esto desperdicia memoria.
        
    - **Limitaci√≥n de tama√±o:** Un proceso no puede ser m√°s grande que la partici√≥n m√°s grande disponible.
        
    - **Grado de multiprogramaci√≥n limitado:** El n√∫mero de procesos que pueden estar en memoria al mismo tiempo es igual al n√∫mero de particiones.
#### Particiones Din√°micas
En el m√©todo de **particiones din√°micas**, la memoria **no se particiona de antemano**. Cuando un proceso necesita cargarse, se le asigna un bloque de memoria contiguo exactamente del tama√±o que requiere. La partici√≥n se crea "sobre la marcha" y su tama√±o es igual al tama√±o del proceso.

- **Ventajas:**
    
    - **Sin fragmentaci√≥n interna:** La memoria se asigna en el tama√±o exacto del proceso, eliminando el desperdicio de memoria dentro de la partici√≥n.
        
    - **Uso eficiente de la memoria:** Se utiliza la cantidad de memoria que realmente se necesita.
        
- **Desventajas:**
    
    - **Fragmentaci√≥n externa:** A medida que los procesos se cargan y se liberan, pueden quedar peque√±os bloques de memoria libre dispersos. Aunque el espacio total libre sea suficiente para un nuevo proceso, puede que no haya un solo bloque contiguo lo suficientemente grande. Esto puede llevar a la necesidad de **compactaci√≥n** de la memoria, que es un proceso costoso.
        
    - **Mayor complejidad:** La gesti√≥n de la memoria es m√°s compleja, ya que el kernel debe llevar un registro de todos los bloques de memoria libres y ocupados.

### b.‚Äã ¬øQu√© informaci√≥n debe disponer el Kernel para poder administrar la memoria principal con estos m√©todos?
Para administrar la memoria principal con estos m√©todos, el **kernel** del sistema operativo necesita mantener un registro de la siguiente informaci√≥n:

- **Informaci√≥n de las particiones (Fijas):** Para cada partici√≥n, el kernel debe saber su direcci√≥n de inicio y su tama√±o.
    
- **Mapa de bits de la memoria (Din√°micas):** El kernel puede usar una estructura de datos como un mapa de bits para representar el estado de la memoria. Cada bit podr√≠a representar un bloque de memoria (por ejemplo, 1KB), indicando si est√° libre (0) u ocupado (1).
    
- **Lista de bloques libres y ocupados (Din√°micas):** Alternativamente, el kernel puede mantener dos listas enlazadas: una para los bloques de memoria libre y otra para los bloques ocupados. Cada entrada en la lista contendr√≠a la direcci√≥n de inicio del bloque y su tama√±o.
    
- **Informaci√≥n de los procesos:** Para cada proceso, el kernel necesita conocer su **direcci√≥n de inicio en memoria f√≠sica** y su **tama√±o**. Esta informaci√≥n es crucial para la asignaci√≥n y liberaci√≥n de memoria.
### c.‚Äã Realice un gr√°fico indicando c√≥mo se realiza la transformaci√≥n de direcciones l√≥gicas a direcciones f√≠sicas.
La transformaci√≥n de direcciones l√≥gicas a f√≠sicas es un proceso fundamental en la gesti√≥n de memoria. Una **direcci√≥n l√≥gica** es la que genera el procesador, mientras que una **direcci√≥n f√≠sica** es la direcci√≥n real en la memoria principal. En el esquema de particiones, esta transformaci√≥n se realiza de la siguiente manera:

1. **El procesador genera una direcci√≥n l√≥gica.** Esta direcci√≥n consta de un **desplazamiento** (offset) desde el inicio del espacio de direcciones del proceso.
    
2. **El hardware de gesti√≥n de memoria (MMU)** toma esta direcci√≥n l√≥gica.
    
3. **Se suma la direcci√≥n de inicio de la partici√≥n.** El kernel le proporciona a la MMU la direcci√≥n de inicio de la partici√≥n en la que se carg√≥ el proceso.
    
4. **Se obtiene la direcci√≥n f√≠sica.** Al sumar la direcci√≥n de inicio de la partici√≥n a la direcci√≥n l√≥gica (desplazamiento), se obtiene la direcci√≥n f√≠sica real en la memoria principal.
    

Esta operaci√≥n se puede expresar con la siguiente f√≥rmula:

**Direcci√≥n F√≠sica = Direcci√≥n de Inicio de la Partici√≥n + Direcci√≥n L√≥gica**

---
## 26. Al trabajar con particiones fijas:
Los tama√±os de las mismas se pueden considerar :
- Particiones de igual tama√±o
- Particiones din√°micas
Citar ventajas y desventajas entre las alternativas

### Particiones de igual tama√±o
A cada proceso se le asigna una partici√≥n, siempre que su tama√±o sea menor o igual.
Ventajas
- Simplicidad: la gesti√≥n es simple, el kernel solo necesita una lista o mapa de bits para saber que particiones est√°n libres u ocupadas.
- Bajo overhead:: No se requiere una gran cantidad de c√°lculos para la asignaci√≥n de memoria.
Desventajas
- Desperdicio de memoria: Si los procesos tienen tama√±os muy variados, este m√©todo es ineficiente. Un proceso peque√±o desperdiciar√≠a una gran cantidad de espacio en la partici√≥n.
- Limitaci√≥n de tama√±o: Un proceso no puede ejecutarse si es m√°s grande que el tama√±o de la partici√≥n.
### Particiones de diferente tama√±o
Se intenta de tener una variedad de tama√±os para acomodar procesos peque√±os, medianos y grandes.
Ventajas
- Menor desperdicio de memoria: Al tener particiones de diferentes tama√±os, se puede asignar a un proceso una partici√≥n m√°s adecuada a su tama√±o, reduciendo la fragmentaci√≥n interna. Un proceso peque√±o puede ir a una partici√≥n peque√±a, y uno grande a una grande
- Mayor flexibilidad: Permite que los procesos de diferentes tama√±os coexistan en la memoria de manera m√°s eficiente.
Desventajas
- Mayor complejidad: El kernel debe buscar la mejor de las particiones en una lista.
- Algoritmos de asignaci√≥n: Se requieren algoritmos de asignaci√≥n (como primer ajuste, mejor ajuste o peor ajuste) para decidir que partici√≥n usar.
---
## 27. Fragmentaci√≥n
Ambos m√©todos de particiones presentan el problema de la fragmentaci√≥n:
‚Äã - Fragmentaci√≥n Interna (Para el caso de Particiones Fijas)
‚Äã - Fragmentaci√≥n Externa (Para el caso de Particiones Din√°micas)

### a.‚Äã Explique a qu√© hacen referencia estos 2 problemas

La **fragmentaci√≥n interna** ocurre cuando a un proceso se le asigna un bloque de memoria m√°s grande de lo que necesita. Esto es com√∫n en el m√©todo de **particiones fijas**. El espacio sobrante dentro del bloque asignado no puede ser utilizado por ning√∫n otro proceso, lo que lleva a un desperdicio de memoria.

Por ejemplo, si un proceso necesita 25KB de memoria y se le asigna una partici√≥n de 30KB, los 5KB restantes son fragmentaci√≥n interna. Esta memoria queda inutilizable hasta que el proceso termine.

La **fragmentaci√≥n externa** se da cuando hay suficiente memoria total disponible para satisfacer una solicitud de un proceso, pero la memoria est√° dispersa en peque√±os bloques no contiguos. Este problema es caracter√≠stico del m√©todo de **particiones din√°micas**, donde los procesos se cargan y descargan, dejando huecos de memoria libre.

Por ejemplo, si un proceso necesita 10KB y hay 5KB libres en una ubicaci√≥n y otros 5KB en otra, el proceso no puede ser cargado porque la memoria no es contigua.

### b.‚Äã El problema de la Fragmentaci√≥n Externa es posible de subsanar. Explique una
El problema de la fragmentaci√≥n externa se puede subsanar mediante una t√©cnica llamada **compactaci√≥n**. La compactaci√≥n es el proceso de reorganizar la memoria para que todos los bloques de memoria libre se unan en un solo bloque contiguo.

La t√©cnica funciona de la siguiente manera:

1. **El kernel detiene la ejecuci√≥n de los procesos.**
    
2. **Mueve los bloques de memoria ocupados.** Todos los procesos que se encuentran en la memoria se desplazan a un extremo de la memoria principal (por lo general, el extremo inferior).
    
3. **Actualiza las direcciones de los procesos.** A medida que los procesos se mueven, sus direcciones de inicio en memoria f√≠sica cambian. El kernel debe actualizar las tablas de direcciones de los procesos para que apunten a sus nuevas ubicaciones.
    
4. **Libera un bloque contiguo.** Una vez que todos los procesos se han movido, todo el espacio libre restante se consolida en un solo bloque grande, listo para ser asignado a un nuevo proceso.
    

Si bien la compactaci√≥n es una soluci√≥n efectiva para la fragmentaci√≥n externa, es una operaci√≥n costosa en t√©rminos de tiempo de CPU y puede causar una interrupci√≥n temporal en la ejecuci√≥n de los procesos. Por esta raz√≥n, no se realiza con frecuencia, sino solo cuando la fragmentaci√≥n externa alcanza un nivel cr√≠tico.

---
## 28. 
Analice y describa c√≥mo funcionan las siguientes t√©cnicas de asignaci√≥n de
particiones: Best Fit, Worst Fit, First Fit y Next Fit. Tenga en cuenta que informaci√≥n
debe mantener el Kernel. Indique, para los m√©todos de particiones din√°micas y
fijas, con cu√°l t√©cnica se obtienen mejores resultados y justifique.

### T√©cnicas de Asignaci√≥n de Particiones

Estas t√©cnicas se utilizan para decidir qu√© partici√≥n de memoria libre se asigna a un nuevo proceso. Para poder aplicar estos algoritmos, el **kernel** debe mantener una **lista enlazada** de todas las particiones de memoria, indicando si est√°n libres u ocupadas, y su direcci√≥n de inicio y tama√±o.

#### First Fit (Primer Ajuste)

- **Funcionamiento:** El kernel busca en la lista de particiones desde el principio y asigna al proceso la **primera partici√≥n libre** que sea lo suficientemente grande para contenerlo.
    
- **Informaci√≥n del Kernel:** Debe tener la lista completa de particiones y un puntero a la √∫ltima partici√≥n asignada para empezar la b√∫squeda en el siguiente punto.
    
- **An√°lisis:** Es la t√©cnica m√°s simple y r√°pida, ya que no necesita buscar la mejor opci√≥n. Sin embargo, puede llevar a una fragmentaci√≥n externa significativa, especialmente si los primeros bloques son peque√±os, dejando los grandes para procesos que podr√≠an no necesitarlos.
    

---

### Next Fit (Siguiente Ajuste)

- **Funcionamiento:** Similar a First Fit, pero la b√∫squeda de la siguiente partici√≥n libre comienza **desde donde termin√≥ la √∫ltima b√∫squeda**, no desde el inicio de la lista.
    
- **Informaci√≥n del Kernel:** Debe mantener un puntero que apunte a la √∫ltima partici√≥n asignada.
    
- **An√°lisis:** Es un poco m√°s r√°pido que First Fit en promedio, ya que distribuye la b√∫squeda por toda la memoria, pero puede generar una fragmentaci√≥n externa a√∫n m√°s dispersa.
    

---

### Best Fit (Mejor Ajuste)

- **Funcionamiento:** El kernel examina toda la lista de particiones libres y asigna al proceso la partici√≥n que sea **la m√°s peque√±a pero a√∫n lo suficientemente grande** para contenerlo. El objetivo es minimizar el espacio sobrante.
    
- **Informaci√≥n del Kernel:** Debe recorrer la lista completa de particiones libres para encontrar la mejor opci√≥n.
    
- **An√°lisis:** Minimiza la fragmentaci√≥n interna al no desperdiciar grandes cantidades de espacio. Sin embargo, puede dejar muchos bloques de memoria muy peque√±os (fragmentaci√≥n externa), que son dif√≠ciles de usar para futuros procesos. Es m√°s lento que First Fit o Next Fit porque requiere una b√∫squeda exhaustiva.
    

---

### Worst Fit (Peor Ajuste)

- **Funcionamiento:** El kernel busca la partici√≥n **m√°s grande** de la lista y se la asigna al proceso. La l√≥gica es que el espacio sobrante de una partici√≥n muy grande ser√° lo suficientemente grande para ser √∫til para otros procesos peque√±os.
    
- **Informaci√≥n del Kernel:** Requiere una b√∫squeda exhaustiva similar a Best Fit para encontrar la partici√≥n m√°s grande.
    
- **An√°lisis:** Intenta evitar la acumulaci√≥n de fragmentos muy peque√±os y in√∫tiles. Sin embargo, al usar el bloque m√°s grande, puede resultar en que un proceso grande que llegue despu√©s no tenga espacio suficiente.
    

---
### Comparativa y Justificaci√≥n

### Particiones Fijas

En las **particiones fijas**, el mejor m√©todo es **Best Fit**. Dado que las particiones tienen un tama√±o fijo, el principal problema es la **fragmentaci√≥n interna**. Al elegir la partici√≥n m√°s ajustada posible (Best Fit), se minimiza el espacio desperdiciado dentro de la partici√≥n asignada. Los otros m√©todos, como First Fit, podr√≠an asignar un proceso peque√±o a una partici√≥n muy grande, aumentando la fragmentaci√≥n interna.

### Particiones Din√°micas

En las **particiones din√°micas**, la principal preocupaci√≥n es la **fragmentaci√≥n externa**. Los m√©todos que funcionan mejor son **First Fit y Next Fit** en t√©rminos de rendimiento general y balance. Aunque Best Fit minimiza la fragmentaci√≥n interna (lo cual no es un problema en particiones din√°micas), su tendencia a dejar peque√±os huecos in√∫tiles (fragmentaci√≥n externa) lo hace menos deseable. Los m√©todos First Fit y Next Fit son m√°s r√°pidos y, aunque contribuyen a la fragmentaci√≥n externa, lo hacen de una manera que puede ser m√°s manejable.

---
## 29. Segmentaci√≥n 
a.‚Äã Explique c√≥mo trabaja este m√©todo de asignaci√≥n de memoria.
b.‚Äã ¬øQu√© estructuras son necesarias en el Kernel para poder ejecutarse sobre un
Hardware que utiliza segmentaci√≥n?
c.‚Äã Explique, utilizando gr√°ficos, c√≥mo son resueltas las direcciones l√≥gicas a
f√≠sicas.
d.‚Äã En este esquema: ¬øse puede producir fragmentaci√≥n (interna y/o externa)?
e.‚Äã De las t√©cnicas enumeradas en el ejercicio 29 ¬øCu√°l se ajusta mejor para la
asignaci√≥n de memoria principal?

### a. Funcionamiento del M√©todo

La **segmentaci√≥n** es un m√©todo de gesti√≥n de memoria que divide el espacio de direcciones de un proceso en bloques l√≥gicos de tama√±o variable llamados **segmentos**. Cada segmento corresponde a una parte l√≥gica del programa (por ejemplo, el c√≥digo, la pila, los datos, etc.). Los segmentos no necesitan ser contiguos en la memoria f√≠sica.

### b. Estructuras del Kernel

Para utilizar segmentaci√≥n, el Kernel debe tener una **tabla de segmentos** para cada proceso. Cada entrada en esta tabla contiene:

- **Direcci√≥n Base:** La direcci√≥n f√≠sica de inicio del segmento en la memoria principal.
    
- **L√≠mite (o Longitud):** El tama√±o del segmento.
    

### c. Resoluci√≥n de Direcciones L√≥gicas a F√≠sicas

La direcci√≥n l√≥gica en un sistema segmentado se compone de dos partes:

- **N√∫mero de Segmento:** Identifica a qu√© segmento pertenece la direcci√≥n.
    
- **Desplazamiento (Offset):** Indica la posici√≥n dentro de ese segmento.
    

La **Unidad de Gesti√≥n de Memoria (MMU)** realiza la traducci√≥n. . El proceso es el siguiente:

1. La MMU recibe una direcci√≥n l√≥gica (segmento, desplazamiento).
    
2. Utiliza el **n√∫mero de segmento** para buscar la entrada correspondiente en la **tabla de segmentos**.
    
3. Comprueba que el **desplazamiento** no supere el **l√≠mite** del segmento para evitar accesos fuera de los l√≠mites. Si es mayor, se genera un error.
    
4. Suma la **direcci√≥n base** del segmento (obtenida de la tabla) al **desplazamiento** para obtener la **direcci√≥n f√≠sica** real en la memoria.
    

### d. Fragmentaci√≥n

- **Fragmentaci√≥n Interna:** No se produce. Los segmentos se asignan con el tama√±o exacto que el proceso requiere, sin dejar espacio no utilizado dentro de ellos.
    
- **Fragmentaci√≥n Externa:** **S√≠ se produce**. A medida que los procesos (o segmentos) se cargan y descargan, la memoria se llena de bloques libres de diferentes tama√±os dispersos, lo que lleva a la fragmentaci√≥n externa, similar a las particiones din√°micas.
    

### e. T√©cnica de Asignaci√≥n

Para la asignaci√≥n de memoria principal en la segmentaci√≥n, las t√©cnicas del Ejercicio 28 son aplicables. **First Fit** y **Next Fit** son las que mejor se ajustan. Como la segmentaci√≥n presenta **fragmentaci√≥n externa**, estas t√©cnicas son eficientes y r√°pidas para encontrar el primer segmento de memoria libre lo suficientemente grande. Aunque Best Fit podr√≠a parecer ideal, su lentitud y la creaci√≥n de peque√±os huecos de memoria lo hacen menos deseable en un sistema de segmentaci√≥n donde la fragmentaci√≥n externa es el principal problema.

---
## 30.
‚ÄãDado un esquema de segmentaci√≥n donde cada direcci√≥n hace referencia a 1 byte y la siguiente tabla de segmentos de un proceso, traduzca, de corresponder, las direcciones l√≥gicas indicadas a direcciones f√≠sicas. La Direcci√≥n l√≥gica est√° representada por: Segmento: deplazamiento


| Segmento | Dir. Base | Tama√±o |
| -------- | --------- | ------ |
| 0        | 102       | 12500  |
| 1        | 28699     | 24300  |
| 2        | 68010     | 15855  |
| 3        | 80001     | 400    |
### i. 0000:9001
base + desplazamiento = Direccion f√≠sica
102 + 9001 = 9103
### ii. 0001:24301
28699 + 24301 = 53000 El desplazamiento cae fuera del espacio de direcciones, operaci√≥n inv√°lida.
### iii. 0002:5678
68010 + 5678 = 73688
### iv. 0001:18976
28699 + 18976 = 47675
### v. 0003:0
80001 + 0 = 80001  

---
## 31. Paginaci√≥n
### a.‚Äã Explique c√≥mo trabaja este m√©todo de asignaci√≥n de memoria.
La **paginaci√≥n** es un m√©todo de asignaci√≥n de memoria no contigua que permite a los procesos residir en fragmentos f√≠sicos de memoria no adyacentes. El objetivo principal de la paginaci√≥n es **resolver el problema de la fragmentaci√≥n externa**.

El sistema divide la memoria f√≠sica en bloques de tama√±o fijo llamados **marcos de p√°gina** (`frames`). Al mismo tiempo, el sistema divide la memoria l√≥gica de cada proceso en bloques del mismo tama√±o llamados **p√°ginas** (`pages`).

Cuando un proceso necesita ejecutarse, el sistema operativo le asigna marcos de p√°gina disponibles en la memoria f√≠sica para almacenar sus p√°ginas l√≥gicas. Los marcos de p√°gina pueden estar dispersos por toda la memoria f√≠sica sin necesidad de ser contiguos. El mapeo entre las p√°ginas l√≥gicas y los marcos de p√°gina f√≠sicos lo realiza el hardware con ayuda del sistema operativo.

### b.‚Äã ¬øQu√© estructuras son necesarias en el Kernel para poder ejecutarse sobre un Hardware que utiliza paginaci√≥n ?
Para que un sistema operativo se ejecute sobre un hardware que utiliza paginaci√≥n, el Kernel necesita al menos las siguientes estructuras de datos principales:

- **Tabla de p√°ginas (`Page Table`):** Es una estructura de datos fundamental, generalmente almacenada en la memoria principal, que contiene la correspondencia entre las p√°ginas l√≥gicas de un proceso y los marcos de p√°gina f√≠sicos en la memoria. Cada proceso en ejecuci√≥n tiene su propia tabla de p√°ginas.
    
- **Registro de tabla de p√°ginas (`Page Table Base Register` o `PTBR`):** Este registro de hardware, ubicado en la **unidad de gesti√≥n de memoria** (`MMU`), apunta a la direcci√≥n de inicio de la tabla de p√°ginas del proceso en ejecuci√≥n.

### c.‚Äã Explique, utilizando gr√°ficos, c√≥mo son resueltas las direcciones l√≥gicas en f√≠sicas.
La resoluci√≥n de una direcci√≥n l√≥gica a una f√≠sica en un esquema de paginaci√≥n se realiza en dos pasos:

1. **Divisi√≥n de la direcci√≥n l√≥gica:** La direcci√≥n l√≥gica se divide en dos partes por el hardware:
    
    - **N√∫mero de p√°gina (`p`):** La parte superior de la direcci√≥n, que se utiliza como √≠ndice para la tabla de p√°ginas.
        
    - **Desplazamiento (`d`):** La parte inferior de la direcci√≥n, que indica la posici√≥n dentro de la p√°gina.
        
2. **Traducci√≥n de la direcci√≥n:** La **Unidad de Gesti√≥n de Memoria (`MMU`)** utiliza el **n√∫mero de p√°gina** para buscar en la **tabla de p√°ginas del proceso** (cuya direcci√≥n est√° en el PTBR). El valor en la entrada de la tabla de p√°ginas correspondiente a `p` contiene el **n√∫mero de marco de p√°gina** f√≠sico (`f`). La direcci√≥n f√≠sica se construye concatenando el n√∫mero de marco de p√°gina (`f`) y el desplazamiento (`d`).
    

Direccion¬†logica:¬†(p,d)

DireccioÀän¬†fƒ±sica:¬†(f,d)

Donde f es el n√∫mero de marco de p√°gina que se encuentra en la entrada p de la tabla de p√°ginas.
### d.‚Äã En este esquema: ¬øse puede producir fragmentaci√≥n (interna y/o externa)?
En este esquema, se puede producir **fragmentaci√≥n interna**, pero **no fragmentaci√≥n externa**.

- **Fragmentaci√≥n interna:** Ocurre si el tama√±o de un proceso no es un m√∫ltiplo exacto del tama√±o de la p√°gina. La √∫ltima p√°gina del proceso puede no llenarse por completo, dejando un espacio no utilizado dentro de un marco de p√°gina. Este espacio es memoria desperdiciada que no puede ser asignada a otro proceso.
    
- **Fragmentaci√≥n externa:** Es la memoria libre que est√° dispersa en peque√±os bloques entre bloques de memoria asignados. La paginaci√≥n evita este problema al permitir que los procesos residan en marcos de p√°gina no contiguos, eliminando la necesidad de buscar un bloque de memoria contiguo lo suficientemente grande para todo el proceso.
---
## 32. Suponga un sistema donde la memoria es administrada mediante la t√©cnica de paginaci√≥n, y donde:
- El tama√±o de la p√°gina es de 512 bytes
- Cada direcci√≥n de memoria referencia 1 byte.
- Se tiene una memoria principal de 10240 bytes (10 KiB) y los marcos enumeran desde 0 y comienzan en la direcci√≥n f√≠sica 0.
Suponga adem√°s un proceso P1 con un tama√±o l√≥gico de 2000 bytes y con la siguiente tabla de p√°ginas:

| P√°gina | Marco |
| ------ | ----- |
| 0      | 3     |
| 1      | 5     |
| 2      | 2     |
| 3      | 6     |
### a. Realice los gr√°ficos necesarios (de la memoria principal, del espacio de direcciones del proceso, de tabla de p√°ginas y de la tabla de marcos) en el que refleje el estado descripto.
num marco * tam pagina = base
num marco sig * tam pag - 1 = l√≠mite

| Marco | Inicio-Fin |
| ----- | ---------- |
| 0     | 0-511      |
| 1     | 512-1023   |
| 2     | 1024-1535  |
| 3     | 1536-2047  |
| 4     | 2048-2559  |
| 5     | 2560-3071  |
| 6     | 3072-3583  |
### b. Indicar si las siguientes direcciones l√≥gicas corresponden al espacio l√≥gico del proceso P1 y en caso afirmativo indicar la direcci√≥n f√≠sica a la que corresponden.
>[!tip] Div con la calculadora
> El resto entero de la divisi√≥n
> Ejemplo : 15 / 4 = 3.75 
> Res = 3

>[!tip] Mod con calculadora
>**F√≥rmula:** a(modb)= a ‚àí (parte¬†entera¬†de¬†(a√∑b)) √ó b
>**Ejemplo:** ¬øCu√°nto es 15(mod4)?
>1. Calcula 15 / 4 = 3.75
>2. La parte entera es 3
>3. Multiplicar esa parte por el divisor: 3x4 = 12
>4. Restar el resultado del dividendo : 15 - 12 = 3
>5. Modulo es 3.

>[!danger] De l√≥gica a f√≠sica
>P√°gina = DL div Tama√±o p√°gina
>Desplazamiento = DL mod Tama√±o p√°gina
>DF = (marco X tam p√°gina ) + desplazamiento
#### i. 35
35 div 512 = 0 (p√°gina 0, corresponde al marco 3)
35 mod 512 = 35 desplazamiento
Direcci√≥n f√≠sica = marco X tam pag) + desplazamiento
1536 + 35 = 1571 v√°lida porque est√° dentro del rango!
#### ii. 512
512 div 512 = 1 ( p√°gina 1, marco 5)
512 mod 512 = 0 desplazamiento
Direcci√≥n f√≠sica = 2560 + 0 = 2560 v√°lida est√° dentro del rango
#### iii. 2051
2051 div 512 = 4 (p√°gina 4, no est√° en la tabla del proceso, direcci√≥n inv√°lida)
#### iv. 0
0 div 512 = 0 (p√°gina 0, marco 3)
0 mod 512 = 0 desplazamiento 
Direcci√≥n f√≠sica = 1536 (dentro de rango direcci√≥n v√°lida)
#### v. 1325
1325 div 512 = 2 (p√°gina 2, corresponde al marco 2)
1325 mod 512 = 301 desplazamiento
Direcci√≥n f√≠sica = 1024 + 301 = 1325 (dentro del rango direcci√≥n v√°lida)
#### vi. 602
602 div 512 = 1 (p√°gina 1, corresponde marco 5)
605 mod 512 = 93 desplazamiento 
### c. Indicar en caso de ser posible, las direcciones l√≥gicas del proceso p1 que se corresponden a las siguientes direcciones f√≠sicas
>[!danger] de fisicas a l√≥gicas
>marco = DF / Tam pag
>desplazamiento = Df mod tam Pag
>DL = (p√°gina x tama√±o de p√°gina) + desplazamiento
#### i. 509
509 div 512 = 0 (marco 0 no se corresponde con ninguna p√°gina)
#### ii.1500
1500 div 512 = 2 (marco 2 corresponde con p√°gina 2)
1500 mod 512 = 476 desplazamiento
Direcci√≥n l√≥gica = 2 * 512 + 476  = 1500 
#### iii.0
0 div 512 = 0 (marco 0 no se corresponde con ninguna p√°gina)
#### iv. 3215
3215 div 512 = 6 (marco 6 se corresponde con p√°gina 3)
3215 mod 512 = 143 desplazamiento
Direcci√≥n L√≥gica = 3 * 512 +143 = 1679 
#### v. 1024
1024 div 512 = 2 (marco 2 se corresponde con p√°gina 2)
1024 mod 512 = 0 desplazamiento
Direcci√≥n l√≥gica = 2 * 512 + 0 = 1024
#### vi. 2000
2000 div 512 = 3 (marco 3, se corresponde a pagina 0)
2000 mod 512 = 464 desplazamiento
Direcci√≥n l√≥gica = 0 * 521 + 464 = 464